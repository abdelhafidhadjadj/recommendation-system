"""
Elasticsearch ‚Äî Mappings et initialisation des index
Syst√®me de recommandation d'articles scientifiques
USTHB ‚Äî PFE Master Bioinformatique 2025/2026

Ce fichier d√©finit la structure des index Elasticsearch,
notamment le champ dense_vector pour les embeddings BioBERT.
"""

import os
import logging
import time
from elasticsearch import Elasticsearch

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ============================================================
# CONNEXION ELASTICSEARCH
# ============================================================
ES_URL = os.getenv("ES_URL", "http://localhost:9200")
ES_INDEX_ARTICLES = os.getenv("ES_INDEX_ARTICLES", "articles")
ES_EMBEDDING_DIMS = int(os.getenv("ES_EMBEDDING_DIMS", "768"))


def get_es_client() -> Elasticsearch:
    """Cr√©e et retourne un client Elasticsearch."""
    client = Elasticsearch(
        ES_URL,
        request_timeout=30,
        retry_on_timeout=True,
        max_retries=3
    )
    return client


def wait_for_elasticsearch(es: Elasticsearch, max_retries: int = 20):
    """
    Attend qu'Elasticsearch soit pr√™t.
    Utile au d√©marrage Docker quand ES met ~30s √† d√©marrer.
    """
    for attempt in range(max_retries):
        try:
            health = es.cluster.health(wait_for_status='yellow', timeout='10s')
            logger.info(f"‚úÖ Elasticsearch pr√™t ‚Äî statut : {health['status']}")
            return True
        except Exception as e:
            logger.warning(f"‚è≥ Tentative {attempt+1}/{max_retries} ‚Äî ES pas encore pr√™t : {e}")
            time.sleep(5)
    raise ConnectionError("‚ùå Elasticsearch inaccessible apr√®s plusieurs tentatives")


# ============================================================
# MAPPING : INDEX ARTICLES
# C'est le mapping le plus important du projet
# Le champ "embedding" est le c≈ìur de la recherche vectorielle
# ============================================================
ARTICLES_MAPPING = {
    "settings": {
        "number_of_shards": 3,       # 3 shards = traitement parall√®le
        "number_of_replicas": 0,     # 0 r√©plique en dev (1 en prod)

        # Analyseur sp√©cialis√© pour le texte scientifique
        "analysis": {
            "analyzer": {
                "scientific_analyzer": {
                    "type": "custom",
                    "tokenizer": "standard",
                    "filter": [
                        "lowercase",
                        "stop",
                        "snowball",      # racinisation (stemming)
                        "asciifolding"   # normalise les accents
                    ]
                }
            }
        },

        # Configuration de la recherche kNN (vecteurs)
        # HNSW = Hierarchical Navigable Small World
        # C'est l'algorithme ANN utilis√© par Elasticsearch
        "index": {
            "knn": True,
            "knn.algo_param.ef_search": 100  # pr√©cision vs vitesse
        }
    },

    "mappings": {
        "properties": {

            # ‚îÄ‚îÄ Identifiants ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            "id": {
                "type": "keyword",  # keyword = valeur exacte, pas analys√©e
                "doc_values": True
            },
            "source": {
                "type": "keyword"  # pubmed | arxiv | s2orc
            },

            # ‚îÄ‚îÄ Contenu textuel ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            "title": {
                "type": "text",
                "analyzer": "scientific_analyzer",
                # "fields" permet d'avoir deux repr√©sentations :
                # title = full-text search
                # title.keyword = valeur exacte (pour tri/agr√©gations)
                "fields": {
                    "keyword": {
                        "type": "keyword",
                        "ignore_above": 512
                    }
                }
            },
            "abstract": {
                "type": "text",
                "analyzer": "scientific_analyzer"
            },

            # ‚îÄ‚îÄ Auteurs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            "authors": {
                "type": "keyword"  # Liste de strings exacts
            },

            # ‚îÄ‚îÄ Mots-cl√©s ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            "keywords": {
                "type": "keyword"
            },
            "keywords_extracted": {
                "type": "keyword",  # Mots-cl√©s extraits par KeyBERT
                "doc_values": True
            },

            # ‚îÄ‚îÄ Dates et m√©triques ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            "publication_date": {
                "type": "date",
                "format": "yyyy-MM-dd||yyyy-MM||yyyy||epoch_millis"
            },
            "journal": {
                "type": "keyword"
            },
            "citations_count": {
                "type": "integer",
                "doc_values": True
            },
            "domain": {
                "type": "keyword"
            },

            # ‚îÄ‚îÄ DOI ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            "doi": {
                "type": "keyword"
            },

            # ‚îÄ‚îÄ Champs sp√©cifiques PubMed ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            "pmid": {
                "type": "keyword"
            },
            "mesh_terms": {
                "type": "keyword"
            },

            # ‚îÄ‚îÄ Champs sp√©cifiques arXiv ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            "arxiv_id": {
                "type": "keyword"
            },
            "arxiv_categories": {
                "type": "keyword"
            },

            # ‚îÄ‚îÄ Mod√®le d'embedding utilis√© ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            "embedding_model": {
                "type": "keyword"  # biobert | scibert | pubmedbert
            },

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # CHAMP VECTORIEL ‚Äî LE PLUS IMPORTANT DU MAPPING
            #
            # dense_vector stocke l'embedding BioBERT/SciBERT
            # de l'article (768 dimensions)
            #
            # index: true ‚Üí active la recherche kNN HNSW
            # similarity: cosine ‚Üí mesure de similarit√© cosinus
            #   (distance angulaire entre vecteurs)
            #   Cosinus est pr√©f√©r√© √† euclidienne pour les embeddings
            #   de texte car il mesure l'orientation, pas la magnitude
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            "embedding": {
                "type": "dense_vector",
                "dims": ES_EMBEDDING_DIMS,   # 768 pour BERT
                "index": True,
                "similarity": "cosine",
                "index_options": {
                    "type": "hnsw",
                    "m": 16,            # nb de connexions par n≈ìud HNSW
                    "ef_construction": 100  # pr√©cision lors de l'indexation
                }
            }
        }
    }
}

# ============================================================
# MAPPING : INDEX USER PROFILES
# Profils vectoriels des utilisateurs pour recherche rapide
# ============================================================
USER_PROFILES_MAPPING = {
    "settings": {
        "number_of_shards": 1,
        "number_of_replicas": 0
    },
    "mappings": {
        "properties": {
            "user_id": {
                "type": "keyword"
            },
            "embedding_model": {
                "type": "keyword"
            },
            "articles_count": {
                "type": "integer"
            },
            "top_domains": {
                "type": "keyword"
            },
            "top_keywords": {
                "type": "keyword"
            },
            "computed_at": {
                "type": "date"
            },
            # Vecteur profil de l'utilisateur
            "profile_vector": {
                "type": "dense_vector",
                "dims": ES_EMBEDDING_DIMS,
                "index": True,
                "similarity": "cosine"
            }
        }
    }
}


# ============================================================
# FONCTIONS D'INITIALISATION
# ============================================================

def create_index(es: Elasticsearch, index_name: str, mapping: dict) -> bool:
    """
    Cr√©e un index si il n'existe pas d√©j√†.
    Retourne True si cr√©√©, False si d√©j√† existant.
    """
    try:
        if es.indices.exists(index=index_name):
            logger.info(f"üìã Index '{index_name}' existe d√©j√† ‚Äî pas de recr√©ation")
            return False

        es.indices.create(index=index_name, body=mapping)
        logger.info(f"‚úÖ Index '{index_name}' cr√©√© avec succ√®s")
        return True

    except Exception as e:
        logger.error(f"‚ùå Erreur cr√©ation index '{index_name}': {e}")
        raise


def delete_and_recreate_index(es: Elasticsearch, index_name: str, mapping: dict):
    """
    Supprime et recr√©e un index.
    ATTENTION : supprime toutes les donn√©es !
    Utile seulement en d√©veloppement pour repartir de z√©ro.
    """
    try:
        if es.indices.exists(index=index_name):
            es.indices.delete(index=index_name)
            logger.warning(f"üóëÔ∏è  Index '{index_name}' supprim√©")

        es.indices.create(index=index_name, body=mapping)
        logger.info(f"‚úÖ Index '{index_name}' recr√©√©")

    except Exception as e:
        logger.error(f"‚ùå Erreur recr√©ation index '{index_name}': {e}")
        raise


def setup_all_indexes(recreate: bool = False):
    """
    Initialise tous les index Elasticsearch n√©cessaires.

    Args:
        recreate: Si True, supprime et recr√©e les index existants.
                  Mettre True seulement en d√©veloppement !
    """
    es = get_es_client()

    try:
        wait_for_elasticsearch(es)

        indexes = [
            (ES_INDEX_ARTICLES, ARTICLES_MAPPING),
            ("user_profiles_es", USER_PROFILES_MAPPING),
        ]

        for index_name, mapping in indexes:
            if recreate:
                delete_and_recreate_index(es, index_name, mapping)
            else:
                create_index(es, index_name, mapping)

        # V√©rification finale
        logger.info("\nüìä √âtat des index Elasticsearch :")
        for index_name, _ in indexes:
            if es.indices.exists(index=index_name):
                stats = es.indices.stats(index=index_name)
                doc_count = stats['_all']['primaries']['docs']['count']
                logger.info(f"   {index_name}: {doc_count} documents")

    finally:
        es.close()


def get_index_stats(index_name: str = None) -> dict:
    """Retourne les statistiques d'un index ou de tous les index."""
    es = get_es_client()
    try:
        target = index_name if index_name else "_all"
        return es.indices.stats(index=target)
    finally:
        es.close()


# ============================================================
# EX√âCUTION DIRECTE
# python storage/elasticsearch/mappings.py
# ============================================================
if __name__ == "__main__":
    import sys

    recreate = "--recreate" in sys.argv
    if recreate:
        logger.warning("‚ö†Ô∏è  Mode RECREATE activ√© ‚Äî les donn√©es existantes seront supprim√©es !")

    setup_all_indexes(recreate=recreate)
    logger.info("‚úÖ Elasticsearch configur√© avec succ√®s")